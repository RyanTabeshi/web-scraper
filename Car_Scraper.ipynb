{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this project, a web scraper will be built to scrape vehicle images (and other features) into a MySQL database for later analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from the necessary modules.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import urlretrieve\n",
    "import re\n",
    "import pymysql\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1: E999 SyntaxError: invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load pycodestyle_mage and run flake8 to check code compliance with PEP8\n",
    "standards.\n",
    "\"\"\"\n",
    "\n",
    "%load_ext pycodestyle_magic\n",
    "%flake8_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a short function that uses a driver object to get the\n",
    "HTML page source, which can be used to create a BeautifulSoup\n",
    "object for parsing.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def driver_page_source(sel_driver):\n",
    "    \"\"\"\n",
    "    Function that uses the driver to return the page source\n",
    "    that is then used to create a BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    page_source = sel_driver.page_source\n",
    "    soup_obj = BeautifulSoup(page_source, 'html.parser')\n",
    "    return soup_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a function that will connect to the MySQL database and enter\n",
    "the data from the variables into the database.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def store_data(year, make, model, kms, private, image1, image2, image3,\n",
    "               price):\n",
    "    \"\"\"\n",
    "    This function will transfer the vehicle data from each vehicle\n",
    "    into the MySQL database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connect to database with connection object.\n",
    "        conn = pymysql.connect(host='localhost', user='root',\n",
    "                               passwd='Afshin123', db='mysql', charset='utf8')\n",
    "        # Use connection object to create cursor.\n",
    "        cur = conn.cursor()\n",
    "        # Use cursor to execute SQL commands.\n",
    "        cur.execute('USE Images_DB')\n",
    "        cur.execute('INSERT INTO Cars_Practice (Car_Year, Car_Make, Car_Model,'\n",
    "                    'Car_Kms, Car_Private, Car_Image1, Car_Image2, Car_Image3,'\n",
    "                    'Car_Price) VALUES (\"{}\", \"{}\", \"{}\", \"{}\", \"{}\", \"{}\",'\n",
    "                    '\"{}\", \"{}\", \"{}\")'.format(year, make, model, kms,\n",
    "                                               private, image1, image2, image3,\n",
    "                                               price))\n",
    "        # Commit the information to the database.\n",
    "        cur.connection.commit()\n",
    "        # Ensure connection/cursor objects are closed.\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a function that will alter the image for the project purposes.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def alter_image(downloaded_image):\n",
    "    \"\"\"\n",
    "    This function will take in a downloaded image with the drive location\n",
    "    of the image, extract the image name, load it into Pillow, convert it\n",
    "    to grayscale, ensure the size is 133x100 pixels, and finally transform\n",
    "    it into, and return, a NumPy array.\n",
    "    \"\"\"\n",
    "    # Get image name only.\n",
    "    image_name = downloaded_image[0]\n",
    "    # Create a Pillow Image object and load it with the image\n",
    "    image_load = Image.open(image_name)\n",
    "    # Change the image to grayscale\n",
    "    image_gs = image_load.convert(mode='L')\n",
    "    # Ensure size of image is 133x100 pixels\n",
    "    image_resize = image_gs.resize((133, 100))\n",
    "    # Transform image to NumPy array\n",
    "    image_array = np.asarray(image_resize)\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Next, create a Selenium driver object to use a Google Chrome\n",
    "webdriver.  Set required options\n",
    "\"\"\"\n",
    "\n",
    "chrome_options = Options()  # Initialize object\n",
    "# chrome_options.add_argument('--headless')\n",
    "# Use fake user-agent header.\n",
    "chrome_options.add_argument('user-agent=Mozilla/5.0 (X11; Ubuntu;'\n",
    "                            'Linux x86_64;rv:68.0) Gecko/20100101'\n",
    "                            'Firefox/68.0')\n",
    "driver = webdriver.Chrome(executable_path='/usr/bin/chromedriver',\n",
    "                          options=chrome_options)\n",
    "website = 'http://www.autotrader.ca/cars/'\n",
    "driver.get(website)\n",
    "time.sleep(random.randint(2, 4))\n",
    "\n",
    "# Click the page once to go to the main page if there is any overlay.\n",
    "actions = ActionChains(driver)\n",
    "actions.move_by_offset(random.randint(50, 75), random.randint(50, 75))\n",
    "actions.click().perform()\n",
    "time.sleep(random.randint(2, 4))\n",
    "\n",
    "# Change the sort parameter so that vehicles are sorted by date,\n",
    "# not by the default sort.  Note, this can also be done with\n",
    "# the URL.\n",
    "sort_select = Select(driver.find_element_by_id('sortBy'))\n",
    "sort_select.select_by_value('CreatedDateDesc')\n",
    "time.sleep(random.randint(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2014', 'TOYOTA', 'HIGHLANDER', 'LE', 'BACKUP', 'CAM', '|', 'BLUETOOTH', '|', 'AUTO', 'HEADLIGHTS', '-', 'MARKHAM']\n",
      "['2019', 'LINCOLN', 'MKZ', 'RESERVE', '-', 'VAUGHAN']\n",
      "['2013', 'JAGUAR', 'XF', '3.0L', 'SUPERCHARGED', 'AWD', 'BLACK/BLACK', 'NAVIGATION', '-', 'NORTH', 'YORK']\n",
      "['2010', 'DODGE', 'RAM', '1500', 'QUAD-HITCH-MARCHEPIEDS++', '-', 'GRANBY']\n",
      "['2015', 'GMC', 'SIERRA', '2500', 'SLE+BOITE', '8', 'PIED+ECRAN.TACT', '-', 'TERREBONNE']\n",
      "['2012', 'CHEVROLET', 'CRUZE', 'LT', 'TURBO', 'W/1SA', '-', 'CALEDONIA']\n",
      "['2017', 'KIA', 'FORTE', '4DR', 'SDN', 'AUTO', 'EX', 'CAMERA', 'DE', 'RECULE', 'PNEU', 'HIVER', '-', 'MCMASTERVILLE']\n",
      "['2013', 'VOLKSWAGEN', 'PASSAT', 'COMFORTLINE', '-', 'BELLEVILLE']\n",
      "['2019', 'NISSAN', 'MURANO', 'PLATINUM', '-', 'ETOBICOKE']\n",
      "['2018', 'BMW', 'X3', 'XDRIVE30I', '-', 'QUÉBEC']\n",
      "['2013', 'TOYOTA', 'RAV4', 'XLE', '|', 'AWD,', 'NAV,', 'SUNROOF,', 'HEATED', 'SEATS,', 'SUNROOF', '-', 'CALEDONIA']\n",
      "['2011', 'MAZDA', 'MAZDA3', 'BERLINE', '4', 'PORTES,', 'BOÎTE', 'AUTOMATIQUE,', 'GX', '-', 'QUEBEC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41:1: W293 blank line contains whitespace\n",
      "55:1: W293 blank line contains whitespace\n",
      "59:56: E128 continuation line under-indented for visual indent\n",
      "59:80: E501 line too long (82 > 79 characters)\n",
      "60:80: E501 line too long (86 > 79 characters)\n",
      "61:80: E501 line too long (83 > 79 characters)\n",
      "67:80: E501 line too long (81 > 79 characters)\n",
      "69:80: E501 line too long (83 > 79 characters)\n",
      "75:80: E501 line too long (82 > 79 characters)\n",
      "91:80: E501 line too long (84 > 79 characters)\n",
      "101:80: E501 line too long (83 > 79 characters)\n",
      "105:80: E501 line too long (81 > 79 characters)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create an empty set of vehicle links.  Create a page loop that will get\n",
    "a page source and use that to return all relevant ad links.\n",
    "If the ad links list returned is not empty, then a random link will be\n",
    "selected from the returned list of links.  If that link is\n",
    "unique, then vehicle information will be gathered.  The driver will\n",
    "then return to the main page and select another randon link to go to.\n",
    "\n",
    "When the loop is completed, we need to then go onto the next page.\n",
    "\"\"\"\n",
    "\n",
    "vehicle_links = set()  # Set ensures information is gathered from unique links.\n",
    "\n",
    "i = 0  # Ad counter\n",
    "k = 0  # Page counter\n",
    "page = 0  # URL counter\n",
    "\n",
    "while k < 2:  # Website page loop\n",
    "    # Use the driver_page_source function to get a BeautifulSoup object.\n",
    "    soup_obj = driver_page_source(driver)\n",
    "    # Use the soup_obj to put ad links for the page into a list.\n",
    "    returned = soup_obj.find_all('a', {'href': re.compile('^(/a/)'),\n",
    "                                 'class': 'main-photo click'})\n",
    "    # If the returned list is not empty, continue into ad loop.\n",
    "    if returned != []:\n",
    "        while i < random.randint(3, len(returned)):\n",
    "            # Select a random link from the list of page links returned\n",
    "            random_link = returned[random.randint(0, len(returned)-1)]\n",
    "            # If the random link is not a duplicate (is unique),\n",
    "            # add it to the set of links\n",
    "            if random_link.attrs['href'] not in vehicle_links:\n",
    "                new_listing_url = random_link.attrs['href']\n",
    "                vehicle_links.add(new_listing_url)\n",
    "                # Go to the unique ad link\n",
    "                driver.get('http://autotrader.ca{}'.format(new_listing_url))\n",
    "                time.sleep(random.randint(5, 7))\n",
    "\n",
    "                # Use driver_page_source function to get the page source\n",
    "                # for the ad.\n",
    "                soup_obj_new = driver_page_source(driver)\n",
    "                \n",
    "                # Use the soup_new_obj to find h1 to get year,\n",
    "                # make, and model of vehicle.\n",
    "                title = soup_obj_new.find('h1').get_text().upper().split()\n",
    "                print(title)\n",
    "                try:\n",
    "                    # The car year should be an integer.\n",
    "                    car_year = int(title[0])\n",
    "                except ValueError:\n",
    "                    # If the string cannot be turned into an integer,\n",
    "                    # leave it as a string and continue.\n",
    "                    car_year = title[0]\n",
    "                car_make = title[1]\n",
    "                car_model = title[2]\n",
    "                \n",
    "                # Next, use the soup object to find the desired images.\n",
    "                vehicle_images = soup_obj_new.find_all('img', {'class':\n",
    "                                                       'col-xs-12 col-md-12'\n",
    "                                                       'vdp-gallery-thumbphotos'})\n",
    "                # With the list of images, only 3 images will be downloaded and placed\n",
    "                # into an image list.  Note that the contents of the below loop can\n",
    "                # easily be made into a function, as well.\n",
    "                j = 0\n",
    "                img_list = []\n",
    "                for image in vehicle_images:\n",
    "                    # Download the image and name it.\n",
    "                    naming = urlretrieve(image['src'], ('photo' + str(k) + str(i)\n",
    "                                                        + str(j)) + '.jpg')\n",
    "                    # Use the alter_image function to return an altered image array\n",
    "                    # and append that image to the list.\n",
    "                    img_list.append(alter_image(naming))\n",
    "                    j += 1\n",
    "                    if j == 3:\n",
    "                        break\n",
    "                # Once out of the loop, use try/except to continue if there are no\n",
    "                # images, or only 1 or 2 images of the vehicle.\n",
    "                try:\n",
    "                    car_image1 = img_list[0]\n",
    "                except IndexError:\n",
    "                    car_image1 = ''\n",
    "                try:\n",
    "                    car_image2 = img_list[1]\n",
    "                except IndexError:\n",
    "                    car_image2 = ''\n",
    "                try:\n",
    "                    car_image3 = img_list[2]\n",
    "                except IndexError:\n",
    "                    car_image3 = ''\n",
    "\n",
    "                # Get kilometers of the vehicle\n",
    "                table_data = soup_obj_new.find('div', {'id': 'vdp-specs-content'}) \\\n",
    "                                         .find('table').find_all('td')\n",
    "                car_kms = table_data[0].get_text().split()[0].replace(',', '')\n",
    "                try:\n",
    "                    car_kms = int(car_kms)\n",
    "                except ValueError:\n",
    "                    car_kms = ''\n",
    "\n",
    "                # Find out if the car is a private sale or not\n",
    "                car_private = 1\n",
    "                if soup_obj_new.find('div', {'class': 'vdp-private-icon'}) is None:\n",
    "                    car_private = 0\n",
    "\n",
    "                # Finally, get the price of the vehicle\n",
    "                car_price = soup_obj_new.find('h2').get_text().replace(',', '') \\\n",
    "                                        .replace('$', '')\n",
    "                try:\n",
    "                    car_price = int(car_price)\n",
    "                except ValueError:\n",
    "                    car_price = ''\n",
    "\n",
    "                # With all of the ad information, this information can now be\n",
    "                # transferred to a database and committed there.\n",
    "                store_data(car_year, car_make, car_model, car_kms, car_private,\n",
    "                           car_image1, car_image2, car_image3, car_price)\n",
    "\n",
    "                i += 1  # Increase loop count for ad.\n",
    "                driver.back()  # Return to ads page.\n",
    "                time.sleep(random.randint(3, 5))\n",
    "            else:\n",
    "                continue\n",
    "        i = 0  # Return inner loop count to 0 for next page of ads.\n",
    "        k += 1  # Increase page count.\n",
    "        page += 15  # Go to the next page with the URL.\n",
    "        driver.get('http://autotrader.ca/cars/?rcp=15&rcs={}&srt=9'\n",
    "                   '&prx=-1&hprc=True&wcp=True&inMarket=advancedSearch'\n",
    "                   .format(str(page)))\n",
    "        time.sleep(random.randint(3, 5))\n",
    "    else:\n",
    "        continue\n",
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
